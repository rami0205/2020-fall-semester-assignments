{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GveZAEwGGTT5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary as summary\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary as summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5E9M_E5HTpr"
   },
   "source": [
    "# 0. 하이퍼 파라미터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eyMXM2PsHTdh"
   },
   "outputs": [],
   "source": [
    "# Device Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Adjust Model Structure Depends on the Data\n",
    "num_classes = 10 # label 0~9: total 10 classes\n",
    "in_channel = 3 # black and white images: 1 channel (RGB: 3 channels)\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 32\n",
    "max_pool_kernel = 2\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ-v6HypG7T6"
   },
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goXDIMEkGhev",
    "outputId": "d1670484-005a-44f7-99ab-1266024153a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./datasets',\n",
    "                                          train=True,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True) # train set 불러오기\n",
    "test_data = torchvision.datasets.CIFAR10(root='./datasets',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True) # test set 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWGF1DdQHHJh"
   },
   "source": [
    "# 2. 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vube3rDwG28l"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G5IJjr8H49C"
   },
   "source": [
    "# 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "V8ZnBS22H2f5"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(ConvNet, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channel, 6, 5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(6),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(max_pool_kernel)\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(6, 16, 5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(max_pool_kernel)\n",
    "    )\n",
    "    self.fc1 = nn.Linear(8*8*16, 120)\n",
    "    self.fc2 = nn.Linear(120, 84)\n",
    "    self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = x.reshape(x.size(0),-1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.softmax(self.fc3(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nPvF8xVfKEf7"
   },
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes).to(device) # model을 GPU에 올린다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3TXxr5jKeG5",
    "outputId": "bce654bd-2fac-49cd-f0b5-fd5bc9a4c229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "# # cf) check the number of parameters\n",
    "# print('{:=^60}'.format(\"=\"))\n",
    "# print('{:^60}'.format(\"model summary\"))\n",
    "# print('{:=^60}'.format(\"=\"))\n",
    "# for param_tensor in model.state_dict():\n",
    "#   print('%-30s'%param_tensor, '{:^30}'.format(str(model.state_dict()[param_tensor].size())))\n",
    "# print('{:=^60}'.format(\"=\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKWjI0AqL7nS"
   },
   "source": [
    "# 4. Loss / Optimizer 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ya0_ApBsH03g"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbjnMH2UL38K"
   },
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yz6sHWQnLqGF",
    "outputId": "b1b8078b-aa28-4a13-ec53-75e8326b55bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1563/1563], Loss: 2.0532, Accuracy: 53.1%\n",
      "Epoch [2/10], Step [1563/1563], Loss: 1.9405, Accuracy: 53.1%\n",
      "Epoch [3/10], Step [1563/1563], Loss: 1.6878, Accuracy: 65.6%\n",
      "Epoch [4/10], Step [1563/1563], Loss: 1.7801, Accuracy: 53.1%\n",
      "Epoch [5/10], Step [1563/1563], Loss: 1.9638, Accuracy: 59.4%\n",
      "Epoch [6/10], Step [1563/1563], Loss: 1.8842, Accuracy: 62.5%\n",
      "Epoch [7/10], Step [1563/1563], Loss: 1.9470, Accuracy: 50.0%\n",
      "Epoch [8/10], Step [1563/1563], Loss: 1.8086, Accuracy: 59.4%\n",
      "Epoch [9/10], Step [1563/1563], Loss: 1.9563, Accuracy: 65.6%\n",
      "Epoch [10/10], Step [1563/1563], Loss: 1.6532, Accuracy: 59.4%\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader) # 1 epoch 당 돌아가는 횟수\n",
    "loss_list = []\n",
    "\n",
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    # Assign Tensors to Configured Device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward Propagation\n",
    "    outputs = model(images)\n",
    "\n",
    "    # Get Loss, Compute Gradient, Update Parameters\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Append loss to plot graph\n",
    "    loss_list.append(loss)\n",
    "\n",
    "    # Print Loss for Tracking Training\n",
    "    # if (i+1) % 100 == 0 or i == len(train_loader)-1:\n",
    "    if i == len(train_loader)-1:\n",
    "      acc = 0\n",
    "      test_image, test_label = next(iter(test_loader))\n",
    "      _, test_predicted = torch.max(model(test_image.to(device)).data, 1)\n",
    "\n",
    "      for (pred, ans) in zip(test_predicted, test_label):\n",
    "        if pred == ans:\n",
    "          acc += 1\n",
    "      acc = acc / len(test_predicted)\n",
    "\n",
    "      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.1f}%'.format(epoch+1,num_epochs, i+1, total_step, loss.item(), acc*100))\n",
    "      # print('Testing data: [Predicted: {} / Real: {}]'.format(test_predicted, test_label))\n",
    "\n",
    "  if epoch+1 == num_epochs:\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "  else:\n",
    "    torch.save(model.state_dict(), 'model-{:02d}_epochs.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNrJrC7sOJ_7",
    "outputId": "5904d6ae-98ee-4dee-cdca-7a3e94c658d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10016 test images 62.43%\n"
     ]
    }
   ],
   "source": [
    "# Test after training is done\n",
    "model.eval() # Set model as evaluation mode (instead of mini-batch mean/var, batchnorm is used)\n",
    "with torch.no_grad(): # auto_grad off\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  print('Accuracy of the network on the {} test images {}%'.format(len(test_loader)*batch_size, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg1qdwyOSntM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_20161147_최하람.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
